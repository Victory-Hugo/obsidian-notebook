<!DOCTYPE html> <html><head>
		<title>将FASTA转换成Arp</title>
		<base href="..\..\../">
		<meta id="root-path" root-path="..\..\../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="思维领域 - 将FASTA转换成Arp">
		<meta property="og:title" content="将FASTA转换成Arp">
		<meta property="og:description" content="思维领域 - 将FASTA转换成Arp">
		<meta property="og:type" content="website">
		<meta property="og:url" content="软件/python/格式转换/将fasta转换成arp.html">
		<meta property="og:image" content="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402201357957.png">
		<meta property="og:site_name" content="思维领域">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="preload" href="lib/styles/other-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/other-plugins.css"></noscript><link rel="stylesheet" href="lib/styles/theme.css"><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/supported-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/supported-plugins.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript></head><body class="publish css-settings-manager theme-dark show-inline-title show-ribbon h2-underline"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles"></style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="将FASTA转换成Arp"><p dir="auto">将FASTA转换成Arp</p></h1><div><p dir="auto">这个脚本可以把FASTA文件转换成Arp，跳过了DnaSP的操作，但是这增加了Arlequin的运算量。需要准备2个文件：</p></div><div><ol>
<li data-line="0" dir="auto">FASTA文件</li>
<li data-line="1" dir="auto">分组文件<br>
如图所示：</li>
</ol></div><div><hr></div><div><p dir="auto"><img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402201357957.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>
用制表符分隔<br>
<img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402201358078.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"></p></div><div><hr></div><div class="heading-wrapper"><h1 data-heading="警告" dir="auto" class="heading" id="警告">警告</h1><div class="heading-children"><div><p dir="auto">我知道你很急，但你先别急。如果你直接把完整序列的<code>fasta</code>文件拿来处理，也不是不行，只是你可能会遇到<code>Arlequin</code>歇菜。</p></div><div><p dir="auto">为了防止这样的情况发生，我们有必要对上面的fasta文件进行简化，从而减轻计算量。</p></div><div class="heading-wrapper"><h2 data-heading="操作" dir="auto" class="heading" id="操作"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>操作</h2><div class="heading-children"><div><ol>
<li data-line="0" dir="auto">打开<a data-href="MEGA" href="MEGA" class="internal-link" target="_self" rel="noopener">MEGA</a></li>
<li data-line="1" dir="auto">导入原始的<code>fasta</code>文件</li>
<li data-line="2" dir="auto">点击<code>Analyze</code></li>
</ol></div><div><p dir="auto"><img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402211402609.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>
4. 根据实际情况选择<br>
<img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402211403215.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>
5. 打开序列<br>
<img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402211404745.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>
6. 点击<code>Data</code>→<code>Export data</code>。<br>
<img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402211404470.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>
7. 删去gap等。<br>
<img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402211405590.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"><br>
8. 点击OK。导出新的<code>fasta</code>文件，再用这个新的文件进行后续分析。</p></div></div></div></div></div><div class="heading-wrapper"><h1 data-heading="版本一" dir="auto" class="heading" id="版本一">版本一</h1><div class="heading-children"><div><p dir="auto">这个版本将不会输出<code>.hap</code>文件，而是会强制将所有的序列信息和ID原封不动全部保留在<code>.arp</code>文件。这对于<code>Arlequin</code>运算时间会变长。</p></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict

<span class="token comment"># Function to read the file content efficiently</span>
<span class="token keyword">def</span> <span class="token function">read_file</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span>encoding<span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token builtin">file</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">except</span> UnicodeDecodeError<span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'latin1'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token builtin">file</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Read the FASTA and Group files</span>
fasta_file_path <span class="token operator">=</span> <span class="token string">'All_pubilc.fasta'</span>
group_file_path <span class="token operator">=</span> <span class="token string">'新建 Text Document.txt'</span>
arp_file_path <span class="token operator">=</span> <span class="token string">'All.ALN.arp'</span>

fasta_content <span class="token operator">=</span> read_file<span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">)</span>
group_content <span class="token operator">=</span> read_file<span class="token punctuation">(</span>group_file_path<span class="token punctuation">)</span>

<span class="token comment"># Preview the files</span>
fasta_preview <span class="token operator">=</span> fasta_content<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>
group_preview <span class="token operator">=</span> group_content<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span>

fasta_preview<span class="token punctuation">,</span> group_preview

<span class="token comment"># Process the group information</span>
group_dict <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> line <span class="token keyword">in</span> group_content<span class="token punctuation">:</span>
    sample_name<span class="token punctuation">,</span> group_name <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
    group_dict<span class="token punctuation">[</span>group_name<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>sample_name<span class="token punctuation">)</span>

<span class="token comment"># Number of unique groups (NbSamples)</span>
nb_samples <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>group_dict<span class="token punctuation">)</span>

<span class="token comment"># Prepare to match FASTA sequences to their respective groups</span>
sequence_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
current_sample_name <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token keyword">for</span> line <span class="token keyword">in</span> fasta_content<span class="token punctuation">:</span>
    <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'&gt;'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        current_sample_name <span class="token operator">=</span> line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        sequence_dict<span class="token punctuation">[</span>current_sample_name<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">elif</span> current_sample_name <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        sequence_dict<span class="token punctuation">[</span>current_sample_name<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Combine sequence lines</span>
<span class="token keyword">for</span> sample <span class="token keyword">in</span> sequence_dict<span class="token punctuation">:</span>
    sequence_dict<span class="token punctuation">[</span>sample<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sequence_dict<span class="token punctuation">[</span>sample<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Create the .arp file content</span>
arp_content <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"[Profile]"</span><span class="token punctuation">,</span>
    <span class="token string">"   Title = \"Genetic Diversity Analysis\""</span><span class="token punctuation">,</span>
    <span class="token string-interpolation"><span class="token string">f"   NbSamples = </span><span class="token interpolation"><span class="token punctuation">{</span>nb_samples<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span>
    <span class="token string">"   DataType = DNA"</span><span class="token punctuation">,</span>
    <span class="token string">"   GenotypicData = 0"</span><span class="token punctuation">,</span>
    <span class="token string">"   LocusSeparator = NONE"</span><span class="token punctuation">,</span>
    <span class="token string">"   MissingData = \"N\""</span><span class="token punctuation">,</span>
    <span class="token string">"   CompDistMatrix = 1"</span><span class="token punctuation">,</span>
    <span class="token string">""</span><span class="token punctuation">,</span>
    <span class="token string">"[Data]"</span><span class="token punctuation">,</span>
    <span class="token string">""</span>
<span class="token punctuation">]</span>

<span class="token comment"># Adding each group's sample information to the .arp file content</span>
<span class="token keyword">for</span> group_name<span class="token punctuation">,</span> samples <span class="token keyword">in</span> group_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    sample_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>samples<span class="token punctuation">)</span>
    arp_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">"[[Samples]]"</span><span class="token punctuation">)</span>
    arp_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"   SampleName = \"</span><span class="token interpolation"><span class="token punctuation">{</span>group_name<span class="token punctuation">}</span></span><span class="token string">\""</span></span><span class="token punctuation">)</span>
    arp_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"   SampleSize = </span><span class="token interpolation"><span class="token punctuation">{</span>sample_size<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    arp_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">"   SampleData= {"</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> sample <span class="token keyword">in</span> samples<span class="token punctuation">:</span>
        sequence <span class="token operator">=</span> sequence_dict<span class="token punctuation">.</span>get<span class="token punctuation">(</span>sample<span class="token punctuation">,</span> <span class="token string">"N"</span> <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">)</span>
        arp_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"       </span><span class="token interpolation"><span class="token punctuation">{</span>sample<span class="token punctuation">}</span></span><span class="token string"> 1 </span><span class="token interpolation"><span class="token punctuation">{</span>sequence<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    arp_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">"   }"</span><span class="token punctuation">)</span>
    arp_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>

<span class="token comment"># Convert the list to a single string</span>
arp_content_str <span class="token operator">=</span> <span class="token string">'\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>arp_content<span class="token punctuation">)</span>

<span class="token comment"># Previewing the beginning of the arp_content</span>
arp_content_preview <span class="token operator">=</span> <span class="token string">'\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>arp_content<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Save the .arp content to a new file</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>arp_file_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
    <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>arp_content_str<span class="token punctuation">)</span>
</code><button class="copy-code-button">复制</button></pre></div></div></div><div class="heading-wrapper"><h1 data-heading="版本二" dir="auto" class="heading" id="版本二">版本二</h1><div class="heading-children"><div><p dir="auto">这个版本会创建一个映射关系的字典，并把序列信息分开保存至.hap文件中。</p></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">import</span> os
<span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict

<span class="token comment"># 功能函数定义</span>
<span class="token keyword">def</span> <span class="token function">read_group_file</span><span class="token punctuation">(</span>group_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""读取分组文件并创建一个映射关系的字典"""</span>
    group_map <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>group_file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
            parts <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parts<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
                sample_name<span class="token punctuation">,</span> group_name <span class="token operator">=</span> parts
                group_map<span class="token punctuation">[</span>sample_name<span class="token punctuation">]</span> <span class="token operator">=</span> group_name
    <span class="token keyword">return</span> group_map

<span class="token keyword">def</span> <span class="token function">read_fasta_file</span><span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""读取fasta文件并返回一个包含样本名称和序列的字典"""</span>
    fasta_data <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    current_sample <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'&gt;'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                current_sample <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
                fasta_data<span class="token punctuation">[</span>current_sample<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                fasta_data<span class="token punctuation">[</span>current_sample<span class="token punctuation">]</span> <span class="token operator">+=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> fasta_data

<span class="token keyword">def</span> <span class="token function">replace_and_sort_fasta_samples</span><span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">,</span> group_file_path<span class="token punctuation">,</span> output_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""替换fasta文件中的样本名称并排序，然后保存到新的文件中"""</span>
    group_map <span class="token operator">=</span> read_group_file<span class="token punctuation">(</span>group_file_path<span class="token punctuation">)</span>
    fasta_data <span class="token operator">=</span> read_fasta_file<span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">)</span>
    replaced_fasta_data <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> seq <span class="token keyword">in</span> fasta_data<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        group_name <span class="token operator">=</span> group_map<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token string">'Unknown'</span><span class="token punctuation">)</span>
        replaced_fasta_data<span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>group_name<span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{</span>name<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'sequence'</span><span class="token punctuation">:</span> seq<span class="token punctuation">,</span> <span class="token string">'province'</span><span class="token punctuation">:</span> group_name<span class="token punctuation">}</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>output_file_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> output_file<span class="token punctuation">:</span>
        <span class="token keyword">for</span> sample <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>replaced_fasta_data<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> replaced_fasta_data<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'province'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            output_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'&gt;</span><span class="token interpolation"><span class="token punctuation">{</span>sample<span class="token punctuation">}</span></span><span class="token string">\n</span><span class="token interpolation"><span class="token punctuation">{</span>replaced_fasta_data<span class="token punctuation">[</span>sample<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"sequence"</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>

<span class="token comment"># 主执行逻辑</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    base_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop'</span>
    fasta_file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_path<span class="token punctuation">,</span> <span class="token string">'Illumina_mtDNA_Filter_recode.fas'</span><span class="token punctuation">)</span><span class="token comment">#改成你自己文件的名字</span>
    group_file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_path<span class="token punctuation">,</span> <span class="token string">'新建文本文档.txt'</span><span class="token punctuation">)</span><span class="token comment">#改成你自己文件的名字</span>
    output_file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_path<span class="token punctuation">,</span> <span class="token string">'New.fasta'</span><span class="token punctuation">)</span><span class="token comment">#别改！！！Don't change it!</span>

    replace_and_sort_fasta_samples<span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">,</span> group_file_path<span class="token punctuation">,</span> output_file_path<span class="token punctuation">)</span>
<span class="token comment">########################################################################################</span>
<span class="token comment">########################################################################################</span>
<span class="token comment">########################################################################################</span>

<span class="token keyword">import</span> os
<span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict

<span class="token comment"># 设置基本路径</span>
base_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop'</span><span class="token comment">#改成你的文件路径</span>

<span class="token comment"># 文件路径</span>
file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_path<span class="token punctuation">,</span> <span class="token string">'New.fasta'</span><span class="token punctuation">)</span> <span class="token comment">#别改！Don't change it!</span>
new_file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_path<span class="token punctuation">,</span> <span class="token string">'New.arp'</span><span class="token punctuation">)</span><span class="token comment">#别改！Don't change it!</span>
new_file_txt_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_path<span class="token punctuation">,</span> <span class="token string">'New.hap'</span><span class="token punctuation">)</span><span class="token comment">#别改！Don't change it!</span>
header_arp_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_path<span class="token punctuation">,</span> <span class="token string">'开头.arp'</span><span class="token punctuation">)</span><span class="token comment">#别改！Don't change it!</span>
final_arp_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_path<span class="token punctuation">,</span> <span class="token string">'最终.arp'</span><span class="token punctuation">)</span><span class="token comment">#别改！Don't change it!</span>

<span class="token comment"># 读取和解析 New.fasta 文件</span>
sequences <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
        line <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'&gt;'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            parts <span class="token operator">=</span> line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            group <span class="token operator">=</span> parts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            seq_id <span class="token operator">=</span> parts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            sequences<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'group'</span><span class="token punctuation">:</span> group<span class="token punctuation">,</span> <span class="token string">'sequence'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">}</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            sequences<span class="token punctuation">[</span>seq_id<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'sequence'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> line

<span class="token comment"># 计算组别数量</span>
group_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>details<span class="token punctuation">[</span><span class="token string">'group'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> details <span class="token keyword">in</span> sequences<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
Group_Number <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>group_set<span class="token punctuation">)</span>

<span class="token comment"># 初始化用于存储唯一序列及其对应hap类型的字典和统计</span>
unique_sequences <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
group_hap_counts <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token keyword">lambda</span><span class="token punctuation">:</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
hap_counter <span class="token operator">=</span> <span class="token number">1</span>

<span class="token comment"># 分配hap类型并统计</span>
<span class="token keyword">for</span> seq_id<span class="token punctuation">,</span> details <span class="token keyword">in</span> sequences<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    seq <span class="token operator">=</span> details<span class="token punctuation">[</span><span class="token string">'sequence'</span><span class="token punctuation">]</span>
    group <span class="token operator">=</span> details<span class="token punctuation">[</span><span class="token string">'group'</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> seq <span class="token keyword">not</span> <span class="token keyword">in</span> unique_sequences<span class="token punctuation">:</span>
        hap_label <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'Hap_</span><span class="token interpolation"><span class="token punctuation">{</span>hap_counter<span class="token punctuation">}</span></span><span class="token string">'</span></span>
        unique_sequences<span class="token punctuation">[</span>seq<span class="token punctuation">]</span> <span class="token operator">=</span> hap_label
        hap_counter <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        hap_label <span class="token operator">=</span> unique_sequences<span class="token punctuation">[</span>seq<span class="token punctuation">]</span>
    group_hap_counts<span class="token punctuation">[</span>group<span class="token punctuation">]</span><span class="token punctuation">[</span>hap_label<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

<span class="token comment"># 写入New.arp文件</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>new_file_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> new_file<span class="token punctuation">:</span>
    <span class="token keyword">for</span> group<span class="token punctuation">,</span> haps <span class="token keyword">in</span> group_hap_counts<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        new_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'[[Samples]]\nSampleName = "</span><span class="token interpolation"><span class="token punctuation">{</span>group<span class="token punctuation">}</span></span><span class="token string">"\nSampleSize = </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">sum</span><span class="token punctuation">(</span>haps<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">\nSampleData= {{\n'</span></span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> hap<span class="token punctuation">,</span> count <span class="token keyword">in</span> haps<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            new_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'    </span><span class="token interpolation"><span class="token punctuation">{</span>hap<span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{</span>count<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>
        new_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'}}\n\n'</span><span class="token punctuation">)</span>

<span class="token comment"># 写入New.hap文件</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>new_file_txt_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> txt_file<span class="token punctuation">:</span>
    <span class="token keyword">for</span> seq<span class="token punctuation">,</span> hap_label <span class="token keyword">in</span> unique_sequences<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        txt_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>hap_label<span class="token punctuation">}</span></span><span class="token string">\t</span><span class="token interpolation"><span class="token punctuation">{</span>seq<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>

<span class="token comment"># 创建并写入开头.arp文件</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>header_arp_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> header_file<span class="token punctuation">:</span>
    header_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"[Profile]\n   Title = \"Haplotype Data from I fuck DnaSP file\"\n"</span><span class="token punctuation">)</span>
    header_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"   NbSamples = </span><span class="token interpolation"><span class="token punctuation">{</span>Group_Number<span class="token punctuation">}</span></span><span class="token string">\n   DataType = DNA\n   GenotypicData = 0\n"</span></span><span class="token punctuation">)</span><span class="token comment">#如果你的数据是二倍体，需要将GenotypicData = 1</span>
    header_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"   LocusSeparator = NONE\n   MissingData = \"?\"\n   CompDistMatrix = 1\n\n[Data]\n\n"</span><span class="token punctuation">)</span>
    header_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"[[HaplotypeDefinition]]\n   HaplList = EXTERN \"New.hap\"\n\n"</span><span class="token punctuation">)</span>

<span class="token comment"># 将New.arp的内容追加到开头.arp</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>header_arp_path<span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> header_file<span class="token punctuation">,</span> <span class="token builtin">open</span><span class="token punctuation">(</span>new_file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> new_file<span class="token punctuation">:</span>
    header_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>new_file<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 重命名或移动文件以创建最终.arp</span>
os<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>header_arp_path<span class="token punctuation">,</span> final_arp_path<span class="token punctuation">)</span>

<span class="token comment"># 删除生成的New.arp文件</span>
os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>new_file_path<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"最终文件已保存至: </span><span class="token interpolation"><span class="token punctuation">{</span>final_arp_path<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token comment"># 删除位于C:/Users/a/Desktop的New.fasta文件</span>
fasta_file_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>base_path<span class="token punctuation">,</span> <span class="token string">'New.fasta'</span><span class="token punctuation">)</span>
os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"文件 </span><span class="token interpolation"><span class="token punctuation">{</span>fasta_file_path<span class="token punctuation">}</span></span><span class="token string"> 已被删除。"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"给我点个赞如何？"</span><span class="token punctuation">)</span>


</code><button class="copy-code-button">复制</button></pre></div><div class="mod-footer"></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="软件\python\格式转换\将fasta转换成arp.html#将FASTA转换成Arp"><div class="tree-item-contents heading-link" heading-name="将FASTA转换成Arp"><span class="tree-item-title">将FASTA转换成Arp</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="软件\python\格式转换\将fasta转换成arp.html#警告"><div class="tree-item-contents heading-link" heading-name="警告"><span class="tree-item-title">警告</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="软件\python\格式转换\将fasta转换成arp.html#操作"><div class="tree-item-contents heading-link" heading-name="操作"><span class="tree-item-title">操作</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="软件\python\格式转换\将fasta转换成arp.html#版本一"><div class="tree-item-contents heading-link" heading-name="版本一"><span class="tree-item-title">版本一</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="软件\python\格式转换\将fasta转换成arp.html#版本二"><div class="tree-item-contents heading-link" heading-name="版本二"><span class="tree-item-title">版本二</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>