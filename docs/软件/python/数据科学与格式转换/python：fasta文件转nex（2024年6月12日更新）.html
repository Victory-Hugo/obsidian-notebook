<html><head>
		<title>python：FASTA文件转NEX（2024年6月12日更新）</title>
		<base href="..\..\../">
		<meta id="root-path" root-path="..\..\../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="思维领域 - python：FASTA文件转NEX（2024年6月12日更新）">
		<meta property="og:title" content="python：FASTA文件转NEX（2024年6月12日更新）">
		<meta property="og:description" content="思维领域 - python：FASTA文件转NEX（2024年6月12日更新）">
		<meta property="og:type" content="website">
		<meta property="og:url" content="软件/python/数据科学与格式转换/python：fasta文件转nex（2024年6月12日更新）.html">
		<meta property="og:image" content="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/20240612212228.png">
		<meta property="og:site_name" content="思维领域">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="preload" href="lib/styles/other-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/other-plugins.css"></noscript><link rel="stylesheet" href="lib/styles/theme.css"><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/supported-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/supported-plugins.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript></head><body class="publish css-settings-manager theme-dark show-inline-title show-ribbon ctp-latte ctp-macchiato ctp-accent-green anuppuccin-accent-toggle anp-current-line-border-only anp-custom-checkboxes anp-speech-bubble anp-codeblock-numbers anp-list-toggle anp-table-toggle anp-table-auto anp-toggle-preview anp-h1-red anp-h2-peach anp-h3-green anp-h4-teal anp-h5-lavender anp-h6-mauve anp-decoration-toggle anp-bold-green anp-italic-green anp-highlight-yellow anp-canvas-dark-bg"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles">mjx-c.mjx-c2192::before{padding:.511em 1em .011em 0;content:"→"}mjx-c.mjx-c1D443.TEX-I::before{padding:.683em .751em 0 0;content:"P"}mjx-munderover{display:inline-block;text-align:left}mjx-munderover:not([limits=false]){padding-top:.1em}mjx-munderover:not([limits=false])>*{display:block}mjx-msubsup{display:inline-block;text-align:left}mjx-script{display:inline-block;padding-right:.05em;padding-left:.033em}mjx-script>mjx-spacer{display:block}mjx-texatom{display:inline-block;text-align:left}mjx-msub{display:inline-block;text-align:left}mjx-msqrt{display:inline-block;text-align:left}mjx-root{display:inline-block;white-space:nowrap}mjx-surd{display:inline-block;vertical-align:top}mjx-sqrt{display:inline-block;padding-top:.07em}mjx-sqrt>mjx-box{border-top:.07em solid}mjx-sqrt.mjx-tall>mjx-box{padding-left:.3em;margin-left:-.3em}mjx-mover{display:inline-block;text-align:left}mjx-mover:not([limits=false]){padding-top:.1em}mjx-mover:not([limits=false])>*{display:block;text-align:left}mjx-c.mjx-c1D70B.TEX-I::before{padding:.431em .57em .011em 0;content:"π"}mjx-c.mjx-c1D458.TEX-I::before{padding:.694em .521em .011em 0;content:"k"}mjx-c.mjx-c2F::before{padding:.75em .5em .25em 0;content:"/"}mjx-c.mjx-c1D703.TEX-I::before{padding:.705em .469em .01em 0;content:"θ"}mjx-c.mjx-c1D446.TEX-I::before{padding:.705em .645em .022em 0;content:"S"}mjx-c.mjx-c1D460.TEX-I::before{padding:.442em .469em .01em 0;content:"s"}mjx-c.mjx-c2E::before{padding:.12em .278em 0 0;content:"."}mjx-c.mjx-c1D451.TEX-I::before{padding:.694em .52em .01em 0;content:"d"}mjx-c.mjx-c221A.TEX-S4::before{padding:1.75em 1.02em 1.25em 0;content:"√"}mjx-c.mjx-c1D465.TEX-I::before{padding:.442em .572em .011em 0;content:"x"}mjx-c.mjx-cAF::before{padding:.59em .5em 0 0;content:"¯"}mjx-c.mjx-c1D441.TEX-I::before{padding:.683em .888em 0 0;content:"N"}mjx-c.mjx-c1D442.TEX-I::before{padding:.704em .763em .022em 0;content:"O"}mjx-c.mjx-c1D435.TEX-I::before{padding:.683em .759em 0 0;content:"B"}mjx-c.mjx-c1D44E.TEX-I::before{padding:.441em .529em .01em 0;content:"a"}mjx-c.mjx-c5F::before{padding:0 .5em .062em 0;content:"_"}mjx-c.mjx-c1D43A.TEX-I::before{padding:.705em .786em .022em 0;content:"G"}mjx-c.mjx-c1D467.TEX-I::before{padding:.442em .465em .011em 0;content:"z"}mjx-c.mjx-c210E.TEX-I::before{padding:.694em .576em .011em 0;content:"h"}mjx-c.mjx-c1D45C.TEX-I::before{padding:.441em .485em .011em 0;content:"o"}mjx-msup{display:inline-block;text-align:left}mjx-c.mjx-c1D43B.TEX-I::before{padding:.683em .888em 0 0;content:"H"}mjx-c.mjx-c1D437.TEX-I::before{padding:.683em .828em 0 0;content:"D"}mjx-c.mjx-c2212::before{padding:.583em .778em .082em 0;content:"−"}mjx-c.mjx-c2211.TEX-S1::before{padding:.75em 1.056em .25em 0;content:"∑"}mjx-c.mjx-c1D45D.TEX-I::before{padding:.442em .503em .194em 0;content:"p"}mjx-c.mjx-c1D456.TEX-I::before{padding:.661em .345em .011em 0;content:"i"}mjx-c.mjx-c32::before{padding:.666em .5em 0 0;content:"2"}mjx-c.mjx-c1D434.TEX-I::before{padding:.716em .75em 0 0;content:"A"}mjx-c.mjx-c1D440.TEX-I::before{padding:.683em 1.051em 0 0;content:"M"}mjx-c.mjx-c39::before{padding:.666em .5em .022em 0;content:"9"}mjx-c.mjx-c2B::before{padding:.583em .778em .082em 0;content:"+"}mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mi{display:inline-block;text-align:left}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-mn{display:inline-block;text-align:left}mjx-mfrac{display:inline-block;text-align:left}mjx-frac{display:inline-block;vertical-align:.17em;padding:0 .22em}mjx-frac[type="d"]{vertical-align:.04em}mjx-frac[delims]{padding:0 .1em}mjx-frac[atop]{padding:0 .12em}mjx-frac[atop][delims]{padding:0}mjx-dtable{display:inline-table;width:100%}mjx-dtable>*{font-size:2000%}mjx-dbox{display:block;font-size:5%}mjx-num{display:block;text-align:center}mjx-den{display:block;text-align:center}mjx-mfrac[bevelled]>mjx-num{display:inline-block}mjx-mfrac[bevelled]>mjx-den{display:inline-block}mjx-den[align=right],mjx-num[align=right]{text-align:right}mjx-den[align=left],mjx-num[align=left]{text-align:left}mjx-nstrut{display:inline-block;height:.054em;width:0;vertical-align:-.054em}mjx-nstrut[type="d"]{height:.217em;vertical-align:-.217em}mjx-dstrut{display:inline-block;height:.505em;width:0}mjx-dstrut[type="d"]{height:.726em}mjx-line{display:block;box-sizing:border-box;min-height:1px;height:.06em;border-top:.06em solid;margin:.06em -.1em;overflow:hidden}mjx-line[type="d"]{margin:.18em -.1em}mjx-mrow{display:inline-block;text-align:left}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("lib/fonts/mathjax_zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("lib/fonts/mathjax_main-regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("lib/fonts/mathjax_main-bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("lib/fonts/mathjax_math-italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("lib/fonts/mathjax_main-italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("lib/fonts/mathjax_math-bolditalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("lib/fonts/mathjax_size1-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("lib/fonts/mathjax_size2-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("lib/fonts/mathjax_size3-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("lib/fonts/mathjax_size4-regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("lib/fonts/mathjax_ams-regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("lib/fonts/mathjax_calligraphic-regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("lib/fonts/mathjax_calligraphic-bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("lib/fonts/mathjax_fraktur-regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("lib/fonts/mathjax_fraktur-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("lib/fonts/mathjax_sansserif-regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("lib/fonts/mathjax_sansserif-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("lib/fonts/mathjax_sansserif-italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("lib/fonts/mathjax_script-regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("lib/fonts/mathjax_typewriter-regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("lib/fonts/mathjax_vector-regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("lib/fonts/mathjax_vector-bold.woff") format("woff")}mjx-c.mjx-c1D439.TEX-I::before{padding:.68em .749em 0 0;content:"F"}mjx-c.mjx-c1D45F.TEX-I::before{padding:.442em .451em .011em 0;content:"r"}mjx-c.mjx-c1D452.TEX-I::before{padding:.442em .466em .011em 0;content:"e"}mjx-c.mjx-c1D45E.TEX-I::before{padding:.442em .46em .194em 0;content:"q"}mjx-c.mjx-c1D462.TEX-I::before{padding:.442em .572em .011em 0;content:"u"}mjx-c.mjx-c1D45B.TEX-I::before{padding:.442em .6em .011em 0;content:"n"}mjx-c.mjx-c1D450.TEX-I::before{padding:.442em .433em .011em 0;content:"c"}mjx-c.mjx-c1D466.TEX-I::before{padding:.442em .49em .205em 0;content:"y"}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c1D436.TEX-I::before{padding:.705em .76em .022em 0;content:"C"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}</style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="2024年6月12日更新记录"><p dir="auto">2024年6月12日更新记录</p></h1><div class="heading-wrapper"><div class="heading-children"><div><p dir="auto">有些时候我们希望 <code>FASTA</code> 序列的 ID 存在单倍群，但是另一些时候则不希望。这真是一个很糟糕的步骤。<br>
所以我重新修改了，这下直接从终端输入 <code>YES</code> 或者 <code>NO</code> 来进行。</p></div><div><p dir="auto">输入文件：<br>
<img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/20240612212228.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"></p></div><div><p dir="auto">代码：</p></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">import</span> os
<span class="token keyword">from</span> Bio <span class="token keyword">import</span> SeqIO

<span class="token comment"># Paths to the files</span>
input_txt_path <span class="token operator">=</span> <span class="token string">r"C:/Users/victo/Desktop/新建 Text Document.txt"</span>
input_fasta_path <span class="token operator">=</span> <span class="token string">r"C:/Users/victo/Desktop/10K_WMG_REFERENCE.ALN.fasta"</span>
output_fasta_path <span class="token operator">=</span> <span class="token string">r"C:/Users/victo/Desktop/提取序列.fasta"</span>

<span class="token comment"># Read the sample IDs and haplogroups from the input TXT file</span>
sample_info <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>input_txt_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> txt_file<span class="token punctuation">:</span>
    <span class="token comment"># Skip the header</span>
    <span class="token builtin">next</span><span class="token punctuation">(</span>txt_file<span class="token punctuation">)</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> txt_file<span class="token punctuation">:</span>
        parts <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parts<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
            sample_id<span class="token punctuation">,</span> haplogroup <span class="token operator">=</span> parts
            sample_info<span class="token punctuation">[</span>sample_id<span class="token punctuation">]</span> <span class="token operator">=</span> haplogroup

<span class="token comment"># Ask the user if they want to include haplogroup information</span>
include_haplogroup <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"是否需要添加单倍群信息至ID？请输入YES或者NO: "</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'YES'</span>

<span class="token comment"># Read the sequences from the input FASTA file and write the required sequences to the output FASTA file</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>output_fasta_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> output_fasta<span class="token punctuation">:</span>
    <span class="token keyword">for</span> record <span class="token keyword">in</span> SeqIO<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>input_fasta_path<span class="token punctuation">,</span> <span class="token string">"fasta"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        original_id <span class="token operator">=</span> record<span class="token punctuation">.</span><span class="token builtin">id</span>
        <span class="token keyword">if</span> original_id <span class="token keyword">in</span> sample_info<span class="token punctuation">:</span>
            <span class="token keyword">if</span> include_haplogroup<span class="token punctuation">:</span>
                new_id <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>original_id<span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>sample_info<span class="token punctuation">[</span>original_id<span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>
                record<span class="token punctuation">.</span><span class="token builtin">id</span> <span class="token operator">=</span> new_id
                record<span class="token punctuation">.</span>description <span class="token operator">=</span> new_id
            SeqIO<span class="token punctuation">.</span>write<span class="token punctuation">(</span>record<span class="token punctuation">,</span> output_fasta<span class="token punctuation">,</span> <span class="token string">"fasta"</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"提取已经完成. 序列已经保存至：</span><span class="token interpolation"><span class="token punctuation">{</span>output_fasta_path<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

</code><button class="copy-code-button">复制</button></pre></div></div></div><div class="heading-wrapper"><h1 data-heading="2024年4月5日更新记录" dir="auto" class="heading" id="2024年4月5日更新记录">2024年4月5日更新记录</h1><div class="heading-children"><div><p dir="auto">2024年4月5日更新：为了<strong>只提取我们需要的序列并转化为 nex 文件，我将这个功能加入到了代码中</strong>。</p></div></div></div><div class="heading-wrapper"><h1 data-heading="概念" dir="auto" class="heading" id="概念">概念</h1><div class="heading-children"><div><p dir="auto"><code>nex</code>文件用来绘制Network图。<br>
这里提供 Python 代码可以很迅速利用分组文件和 fasta 文件转化成 nex。</p></div></div></div><div class="heading-wrapper"><h1 data-heading="文件准备" dir="auto" class="heading" id="文件准备">文件准备</h1><div class="heading-children"><div><ol>
<li data-line="0" dir="auto">fasta文件</li>
<li data-line="1" dir="auto">分类文件</li>
</ol></div><div><p dir="auto"><code>FASTA</code>文件格式没有特殊要求：<br>
<img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402231407451.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"></p></div><div><p dir="auto">分类文件要求<code>csv</code>格式：<br>
<img alt="image.png" src="https://picturerealm.oss-cn-chengdu.aliyuncs.com/obsidian/202402231407511.png" referrerpolicy="no-referrer" style="width: 500px; max-width: 100%;"></p></div><div><div data-callout-metadata="" data-callout-fold="" data-callout="warning" class="callout"><div class="callout-title" dir="auto"><div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-alert-triangle"><path d="m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3Z"></path><path d="M12 9v4"></path><path d="M12 17h.01"></path></svg></div><div class="callout-title-inner">注意</div></div><div class="callout-content">
<p dir="auto"><code>nex</code>文件对于格式的要求很高。所以注意，上面<code>csv</code>文件中不能出现多余的<code>空格</code>、<code>+-</code>符号等特殊符号。</p>
</div></div></div></div></div><div class="heading-wrapper"><h1 data-heading="代码实例" dir="auto" class="heading" id="代码实例">代码实例</h1><div class="heading-children"><div class="heading-wrapper"><h2 data-heading="用法一" dir="auto" class="heading" id="用法一"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>用法一</h2><div class="heading-children"><div><p dir="auto">以下用法适合文件完全符合上述要求的。</p></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment"># 从没有标题的CSV文件中读取ID列表</span>
csv_file_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/Illumina芯片分析表.csv'</span> <span class="token comment"># 修改路径</span>
nex_file_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/final.nex'</span> <span class="token comment"># 请修改！Change this!</span>
df_no_header <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>csv_file_path<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
<span class="token comment"># 创建一个集合，包含所有的ID</span>
id_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>df_no_header<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 定义一个函数，使用更严格的逻辑从FASTA文件中提取序列</span>
<span class="token keyword">def</span> <span class="token function">read_and_extract_fasta_strict</span><span class="token punctuation">(</span>fasta_path<span class="token punctuation">,</span> ids<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fasta_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fasta_file<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> fasta_file<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    extract <span class="token operator">=</span> <span class="token boolean">False</span>
    extracted_sequences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    current_sequence <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token comment"># 遍历每一行</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"&gt;"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            line_id <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># 提取行中的ID</span>
            <span class="token keyword">if</span> line_id <span class="token keyword">in</span> ids<span class="token punctuation">:</span>
                extract <span class="token operator">=</span> <span class="token boolean">True</span>
                <span class="token keyword">if</span> current_sequence<span class="token punctuation">:</span>
                    extracted_sequences<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_sequence<span class="token punctuation">)</span><span class="token punctuation">)</span>
                    current_sequence <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
                <span class="token comment"># 保持原始ID不变</span>
                updated_id <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"&gt;</span><span class="token interpolation"><span class="token punctuation">{</span>line_id<span class="token punctuation">}</span></span><span class="token string">\n"</span></span>
                current_sequence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>updated_id<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> extract<span class="token punctuation">:</span>
                    extracted_sequences<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_sequence<span class="token punctuation">)</span><span class="token punctuation">)</span>
                    current_sequence <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
                extract <span class="token operator">=</span> <span class="token boolean">False</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> extract<span class="token punctuation">:</span>
                current_sequence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">)</span>
                
    <span class="token keyword">if</span> current_sequence<span class="token punctuation">:</span>
        extracted_sequences<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_sequence<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> extracted_sequences

<span class="token comment"># FASTA文件路径和新FASTA文件保存路径</span>
origin_fasta_file_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/Illumina_mtDNA_Filter_recode.fasta'</span> <span class="token comment"># 指定你的原始fasta路径</span>
extracted_sequence_fasta_file_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/extracted_sequences.fasta'</span> <span class="token comment"># 指定你的提取fasta路径</span>

<span class="token comment"># 使用修正后的函数从FASTA文件中提取序列</span>
extracted_sequences_strict <span class="token operator">=</span> read_and_extract_fasta_strict<span class="token punctuation">(</span>origin_fasta_file_path<span class="token punctuation">,</span> id_set<span class="token punctuation">)</span>

<span class="token comment"># 将提取的序列保存到新的FASTA文件</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>extracted_sequence_fasta_file_path<span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> output_fasta<span class="token punctuation">:</span>
    <span class="token keyword">for</span> sequence <span class="token keyword">in</span> extracted_sequences_strict<span class="token punctuation">:</span>
        output_fasta<span class="token punctuation">.</span>write<span class="token punctuation">(</span>sequence<span class="token punctuation">)</span>

<span class="token comment"># 输出新FASTA文件的路径，表示任务完成</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"提取的序列已保存至: </span><span class="token interpolation"><span class="token punctuation">{</span>extracted_sequence_fasta_file_path<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>


<span class="token comment">##############################################</span>
<span class="token comment">###########现在开始进行fasta序列转化############</span>
<span class="token comment">##############################################</span>

<span class="token comment"># 这个代码的作用是根据分组文件，生成.nex文件</span>
<span class="token comment"># 注意，使用前请将代码中出现的路径（C:/Users/a/Desktop/）全部替换成你的路径（建议设置为桌面）</span>

<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment"># 定义 CSV 文件路径和 FASTA 文件路径</span>
fasta_file_path <span class="token operator">=</span> extracted_sequence_fasta_file_path
new_fasta_file_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/ID_haplogroup.fasta'</span> <span class="token comment"># 输出带有单倍型的fasta文件</span>

<span class="token keyword">try</span><span class="token punctuation">:</span>
    <span class="token comment"># 加载单倍群信息，没有标题行，自定义列名</span>
    haplogroup_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>csv_file_path<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'SampleID'</span><span class="token punctuation">,</span> <span class="token string">'Region'</span><span class="token punctuation">,</span> <span class="token string">'Haplogroup'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 创建 SampleID 到 Haplogroup 的映射字典</span>
    haplogroup_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>haplogroup_df<span class="token punctuation">[</span><span class="token string">'SampleID'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> haplogroup_df<span class="token punctuation">[</span><span class="token string">'Haplogroup'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 同时打开原始 FASTA 文件和新 FASTA 文件进行读写</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> original_fasta<span class="token punctuation">,</span> <span class="token builtin">open</span><span class="token punctuation">(</span>new_fasta_file_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> modified_fasta<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> original_fasta<span class="token punctuation">:</span>
            <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'&gt;'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 这是一个 ID 行</span>
                <span class="token comment"># 提取样本 ID（移除 '&gt;' 和换行符）</span>
                sample_id <span class="token operator">=</span> line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token comment"># 如果字典中存在对应的单倍群，则追加；否则，标记为 'Unknown'</span>
                haplogroup <span class="token operator">=</span> haplogroup_dict<span class="token punctuation">.</span>get<span class="token punctuation">(</span>sample_id<span class="token punctuation">,</span> <span class="token string">'Unknown'</span><span class="token punctuation">)</span>
                <span class="token comment"># 用下划线连接样本 ID 和单倍群</span>
                modified_line <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"&gt;</span><span class="token interpolation"><span class="token punctuation">{</span>sample_id<span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>haplogroup<span class="token punctuation">}</span></span><span class="token string">\n"</span></span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                modified_line <span class="token operator">=</span> line  <span class="token comment"># 序列行保持不变</span>
            modified_fasta<span class="token punctuation">.</span>write<span class="token punctuation">(</span>modified_line<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"FASTA 文件处理完成。"</span><span class="token punctuation">)</span>
<span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"处理过程中发生错误：</span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># 如果需要，可以在这里添加代码以检查和验证新文件的内容</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment"># 定义原 CSV 文件路径和新 CSV 文件路径</span>
new_csv_file_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/do_not_change_myname.csv'</span>  <span class="token comment"># 请不要改变文件名称</span>

<span class="token comment"># 读取 CSV 文件，无标题行，指定列名</span>
haplogroup_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>csv_file_path<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'SampleID'</span><span class="token punctuation">,</span> <span class="token string">'Region'</span><span class="token punctuation">,</span> <span class="token string">'Haplogroup'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 将第一列内容与第三列内容用"_"连接，并替换原本第一列内容</span>
haplogroup_df<span class="token punctuation">[</span><span class="token string">'SampleID'</span><span class="token punctuation">]</span> <span class="token operator">=</span> haplogroup_df<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>x<span class="token punctuation">[</span><span class="token string">'SampleID'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>x<span class="token punctuation">[</span><span class="token string">'Haplogroup'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 删除第三列（Haplogroup）</span>
haplogroup_df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Haplogroup'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 将修改后的 DataFrame 保存为新文件，保留原文件不变</span>
haplogroup_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>new_csv_file_path<span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"新的分类汇总文件已保存至：</span><span class="token interpolation"><span class="token punctuation">{</span>new_csv_file_path<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"分组汇总.csv 文件已更新。"</span><span class="token punctuation">)</span>


<span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># 以下代码请勿更改文件名称，路径设置为刚才的路径（建议设置为桌面）</span>

<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token comment"># 示例调用</span>
fasta_file_path <span class="token operator">=</span> new_fasta_file_path <span class="token comment"># 请勿修改！don't change this!</span>
group_file_path <span class="token operator">=</span> new_csv_file_path <span class="token comment"># 请勿修改！don't change this!</span>

new_csv_path_final <span class="token operator">=</span> <span class="token string">'./grouped_names_final.csv'</span> <span class="token comment"># 请勿修改！don't change this!</span>
<span class="token keyword">def</span> <span class="token function">read_fasta_file</span><span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    samples <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fasta<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> fasta<span class="token punctuation">:</span>
            <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'&gt;'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                current_sample <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>lstrip<span class="token punctuation">(</span><span class="token string">'&gt;'</span><span class="token punctuation">)</span>
                samples<span class="token punctuation">[</span>current_sample<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                samples<span class="token punctuation">[</span>current_sample<span class="token punctuation">]</span> <span class="token operator">+=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> samples

<span class="token keyword">def</span> <span class="token function">create_nex_file</span><span class="token punctuation">(</span>samples<span class="token punctuation">,</span> nex_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ntax <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>samples<span class="token punctuation">)</span>
    nchar <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>samples<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> ntax <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token number">0</span>
    nex_content <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string">"#NEXUS\n\n"</span><span class="token punctuation">,</span>
        <span class="token string">"Begin Data;\n"</span><span class="token punctuation">,</span>
        <span class="token string-interpolation"><span class="token string">f"\tDimensions ntax=</span><span class="token interpolation"><span class="token punctuation">{</span>ntax<span class="token punctuation">}</span></span><span class="token string"> NCHAR=</span><span class="token interpolation"><span class="token punctuation">{</span>nchar<span class="token punctuation">}</span></span><span class="token string">;\n"</span></span><span class="token punctuation">,</span>
        <span class="token string">"\tFormat datatype=DNA missing=N GAP=-;\n"</span><span class="token punctuation">,</span>
        <span class="token string">"\tMATRIX\n"</span>
    <span class="token punctuation">]</span>
    <span class="token keyword">for</span> sample_id<span class="token punctuation">,</span> sequence <span class="token keyword">in</span> samples<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        nex_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\t</span><span class="token interpolation"><span class="token punctuation">{</span>sample_id<span class="token punctuation">}</span></span><span class="token string">\n</span><span class="token interpolation"><span class="token punctuation">{</span>sequence<span class="token punctuation">}</span></span><span class="token string">\n"</span></span><span class="token punctuation">)</span>
    nex_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">";\nEND;\n\n\n"</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>nex_file_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> nex_file<span class="token punctuation">:</span>
        nex_file<span class="token punctuation">.</span>writelines<span class="token punctuation">(</span>nex_content<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_group_file_to_csv</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> new_csv_path_final<span class="token punctuation">)</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Name'</span><span class="token punctuation">,</span> <span class="token string">'Group'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    unique_groups_sorted <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'Group'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    matrix_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token string">'Name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token operator">=</span>unique_groups_sorted<span class="token punctuation">)</span>
    <span class="token keyword">for</span> index<span class="token punctuation">,</span> row <span class="token keyword">in</span> data<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        matrix_df<span class="token punctuation">.</span>at<span class="token punctuation">[</span>row<span class="token punctuation">[</span><span class="token string">'Name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token string">'Group'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    matrix_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    matrix_df<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'index'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">}</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    matrix_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>new_csv_path_final<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">append_traits_to_nex</span><span class="token punctuation">(</span>input_csv<span class="token punctuation">,</span> nex_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>input_csv<span class="token punctuation">)</span>
    new_columns <span class="token operator">=</span> <span class="token punctuation">[</span>col<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span> <span class="token keyword">for</span> col <span class="token keyword">in</span> df<span class="token punctuation">.</span>columns <span class="token keyword">if</span> col <span class="token operator">!=</span> <span class="token string">'Name'</span><span class="token punctuation">]</span>
    ntraits <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>new_columns<span class="token punctuation">)</span>
    trait_labels <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>new_columns<span class="token punctuation">)</span>
    nex_content <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"""Begin Traits;
Dimensions NTraits=</span><span class="token interpolation"><span class="token punctuation">{</span>ntraits<span class="token punctuation">}</span></span><span class="token string">;
Format labels=yes missing=? separator=Comma;
TraitLabels </span><span class="token interpolation"><span class="token punctuation">{</span>trait_labels<span class="token punctuation">}</span></span><span class="token string">;
Matrix \n
"""</span></span>
    <span class="token keyword">for</span> index<span class="token punctuation">,</span> row <span class="token keyword">in</span> df<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        row_data <span class="token operator">=</span> <span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>row<span class="token punctuation">[</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>row<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> col <span class="token keyword">in</span> df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        nex_content <span class="token operator">+=</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>row<span class="token punctuation">[</span><span class="token string">'Name'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{</span>row_data<span class="token punctuation">}</span></span><span class="token string">\n"</span></span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>nex_file_path<span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
        <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>nex_content<span class="token punctuation">)</span>
        <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\t;\n\tend;\n"</span><span class="token punctuation">)</span>



samples <span class="token operator">=</span> read_fasta_file<span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">)</span>
create_nex_file<span class="token punctuation">(</span>samples<span class="token punctuation">,</span> nex_file_path<span class="token punctuation">)</span>
process_group_file_to_csv<span class="token punctuation">(</span>group_file_path<span class="token punctuation">,</span> new_csv_path_final<span class="token punctuation">)</span>
append_traits_to_nex<span class="token punctuation">(</span>new_csv_path_final<span class="token punctuation">,</span> nex_file_path<span class="token punctuation">)</span>

<span class="token comment"># 输出文件路径以便下载</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>nex_file_path<span class="token punctuation">)</span>

<span class="token comment"># 删除新分类汇总.csv</span>
<span class="token keyword">import</span> os
os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>new_csv_path_final<span class="token punctuation">)</span>
os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>group_file_path<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"多余文件已删除。"</span><span class="token punctuation">)</span>


</code><button class="copy-code-button">复制</button></pre></div></div></div><div class="heading-wrapper"><h2 data-heading="用法二" dir="auto" class="heading" id="用法二"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>用法二</h2><div class="heading-children"><div><p dir="auto">如果你的fasta文件已经是自带单倍群信息的了，那就可以只用上述代码的第二部分。</p></div><div><pre class="language-python" tabindex="0"><code class="language-python is-loaded"><span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># ================================================================== #</span>
<span class="token comment"># 以下代码建议设置为桌面</span>

<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token comment"># 示例调用</span>
fasta_file_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/ID_haplogroup.fasta'</span> <span class="token comment"># 替换为自带单倍群的fasta文件，不能有特殊符号</span>
group_file_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/do_not_change_myname.csv'</span>  <span class="token comment"># 替换为分组文件，第一列为ID_单倍群，第二列为分组条件，没有表头</span>
nex_file_path <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/final.nex'</span>  <span class="token comment"># 设置为输出路径</span>
new_csv_path_final <span class="token operator">=</span> <span class="token string">'C:/Users/a/Desktop/grouped_names_final.csv'</span>  
<span class="token keyword">def</span> <span class="token function">read_fasta_file</span><span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    samples <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fasta<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> fasta<span class="token punctuation">:</span>
            <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'&gt;'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                current_sample <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>lstrip<span class="token punctuation">(</span><span class="token string">'&gt;'</span><span class="token punctuation">)</span>
                samples<span class="token punctuation">[</span>current_sample<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                samples<span class="token punctuation">[</span>current_sample<span class="token punctuation">]</span> <span class="token operator">+=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> samples

<span class="token keyword">def</span> <span class="token function">create_nex_file</span><span class="token punctuation">(</span>samples<span class="token punctuation">,</span> nex_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ntax <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>samples<span class="token punctuation">)</span>
    nchar <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>samples<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> ntax <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">else</span> <span class="token number">0</span>
    nex_content <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string">"#NEXUS\n\n"</span><span class="token punctuation">,</span>
        <span class="token string">"Begin Data;\n"</span><span class="token punctuation">,</span>
        <span class="token string-interpolation"><span class="token string">f"\tDimensions ntax=</span><span class="token interpolation"><span class="token punctuation">{</span>ntax<span class="token punctuation">}</span></span><span class="token string"> NCHAR=</span><span class="token interpolation"><span class="token punctuation">{</span>nchar<span class="token punctuation">}</span></span><span class="token string">;\n"</span></span><span class="token punctuation">,</span>
        <span class="token string">"\tFormat datatype=DNA missing=N GAP=-;\n"</span><span class="token punctuation">,</span>
        <span class="token string">"\tMATRIX\n"</span>
    <span class="token punctuation">]</span>
    <span class="token keyword">for</span> sample_id<span class="token punctuation">,</span> sequence <span class="token keyword">in</span> samples<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        nex_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\t</span><span class="token interpolation"><span class="token punctuation">{</span>sample_id<span class="token punctuation">}</span></span><span class="token string">\n</span><span class="token interpolation"><span class="token punctuation">{</span>sequence<span class="token punctuation">}</span></span><span class="token string">\n"</span></span><span class="token punctuation">)</span>
    nex_content<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">";\nEND;\n\n\n"</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>nex_file_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> nex_file<span class="token punctuation">:</span>
        nex_file<span class="token punctuation">.</span>writelines<span class="token punctuation">(</span>nex_content<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_group_file_to_csv</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> new_csv_path_final<span class="token punctuation">)</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Name'</span><span class="token punctuation">,</span> <span class="token string">'Group'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
    unique_groups_sorted <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'Group'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    matrix_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token string">'Name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token operator">=</span>unique_groups_sorted<span class="token punctuation">)</span>
    <span class="token keyword">for</span> index<span class="token punctuation">,</span> row <span class="token keyword">in</span> data<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        matrix_df<span class="token punctuation">.</span>at<span class="token punctuation">[</span>row<span class="token punctuation">[</span><span class="token string">'Name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token string">'Group'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    matrix_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    matrix_df<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'index'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">}</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    matrix_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>new_csv_path_final<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">append_traits_to_nex</span><span class="token punctuation">(</span>input_csv<span class="token punctuation">,</span> nex_file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>input_csv<span class="token punctuation">)</span>
    new_columns <span class="token operator">=</span> <span class="token punctuation">[</span>col<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span> <span class="token keyword">for</span> col <span class="token keyword">in</span> df<span class="token punctuation">.</span>columns <span class="token keyword">if</span> col <span class="token operator">!=</span> <span class="token string">'Name'</span><span class="token punctuation">]</span>
    ntraits <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>new_columns<span class="token punctuation">)</span>
    trait_labels <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>new_columns<span class="token punctuation">)</span>
    nex_content <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"""Begin Traits;
Dimensions NTraits=</span><span class="token interpolation"><span class="token punctuation">{</span>ntraits<span class="token punctuation">}</span></span><span class="token string">;
Format labels=yes missing=? separator=Comma;
TraitLabels </span><span class="token interpolation"><span class="token punctuation">{</span>trait_labels<span class="token punctuation">}</span></span><span class="token string">;
Matrix \n
"""</span></span>
    <span class="token keyword">for</span> index<span class="token punctuation">,</span> row <span class="token keyword">in</span> df<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        row_data <span class="token operator">=</span> <span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>row<span class="token punctuation">[</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>row<span class="token punctuation">[</span>col<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> col <span class="token keyword">in</span> df<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        nex_content <span class="token operator">+=</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>row<span class="token punctuation">[</span><span class="token string">'Name'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{</span>row_data<span class="token punctuation">}</span></span><span class="token string">\n"</span></span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>nex_file_path<span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
        <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>nex_content<span class="token punctuation">)</span>
        <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\t;\n\tend;\n"</span><span class="token punctuation">)</span>



samples <span class="token operator">=</span> read_fasta_file<span class="token punctuation">(</span>fasta_file_path<span class="token punctuation">)</span>
create_nex_file<span class="token punctuation">(</span>samples<span class="token punctuation">,</span> nex_file_path<span class="token punctuation">)</span>
process_group_file_to_csv<span class="token punctuation">(</span>group_file_path<span class="token punctuation">,</span> new_csv_path_final<span class="token punctuation">)</span>
append_traits_to_nex<span class="token punctuation">(</span>new_csv_path_final<span class="token punctuation">,</span> nex_file_path<span class="token punctuation">)</span>

<span class="token comment"># 输出文件路径以便下载</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>nex_file_path<span class="token punctuation">)</span>

<span class="token comment"># 删除新分类汇总.csv</span>
<span class="token keyword">import</span> os
os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>new_csv_path_final<span class="token punctuation">)</span>
os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>group_file_path<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"多余文件已删除。"</span><span class="token punctuation">)</span>
</code><button class="copy-code-button">复制</button></pre></div><div class="mod-footer"></div></div></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="软件\python\数据科学与格式转换\python：fasta文件转nex（2024年6月12日更新）.html#2024年6月12日更新记录"><div class="tree-item-contents heading-link" heading-name="2024年6月12日更新记录"><span class="tree-item-title">2024年6月12日更新记录</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="软件\python\数据科学与格式转换\python：fasta文件转nex（2024年6月12日更新）.html#2024年4月5日更新记录"><div class="tree-item-contents heading-link" heading-name="2024年4月5日更新记录"><span class="tree-item-title">2024年4月5日更新记录</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="软件\python\数据科学与格式转换\python：fasta文件转nex（2024年6月12日更新）.html#概念"><div class="tree-item-contents heading-link" heading-name="概念"><span class="tree-item-title">概念</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="软件\python\数据科学与格式转换\python：fasta文件转nex（2024年6月12日更新）.html#文件准备"><div class="tree-item-contents heading-link" heading-name="文件准备"><span class="tree-item-title">文件准备</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="软件\python\数据科学与格式转换\python：fasta文件转nex（2024年6月12日更新）.html#代码实例"><div class="tree-item-contents heading-link" heading-name="代码实例"><span class="tree-item-title">代码实例</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="软件\python\数据科学与格式转换\python：fasta文件转nex（2024年6月12日更新）.html#用法一"><div class="tree-item-contents heading-link" heading-name="用法一"><span class="tree-item-title">用法一</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="软件\python\数据科学与格式转换\python：fasta文件转nex（2024年6月12日更新）.html#用法二"><div class="tree-item-contents heading-link" heading-name="用法二"><span class="tree-item-title">用法二</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>